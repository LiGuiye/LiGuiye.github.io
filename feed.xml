<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://liguiye.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://liguiye.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-02-21T03:04:13+00:00</updated><id>https://liguiye.github.io/feed.xml</id><title type="html">blank</title><entry><title type="html">Statistical Distributions</title><link href="https://liguiye.github.io/blog/2023/Statistical-Distributions/" rel="alternate" type="text/html" title="Statistical Distributions"/><published>2023-02-01T15:59:00+00:00</published><updated>2023-02-01T15:59:00+00:00</updated><id>https://liguiye.github.io/blog/2023/Statistical-Distributions</id><content type="html" xml:base="https://liguiye.github.io/blog/2023/Statistical-Distributions/"><![CDATA[<p><em>TOC</em></p> <ul id="markdown-toc"> <li><a href="#basic-knowledge" id="markdown-toc-basic-knowledge">Basic knowledge</a></li> <li><a href="#common-distributions" id="markdown-toc-common-distributions">Common distributions</a> <ul> <li><a href="#symmetric-probability-distribution" id="markdown-toc-symmetric-probability-distribution">Symmetric probability distribution</a></li> <li><a href="#uniform-distribution" id="markdown-toc-uniform-distribution">Uniform distribution</a></li> <li><a href="#bernoulli-distribution" id="markdown-toc-bernoulli-distribution">Bernoulli distribution</a></li> <li><a href="#binomial-distribution" id="markdown-toc-binomial-distribution">Binomial distribution</a></li> <li><a href="#negative-binomial-distribution" id="markdown-toc-negative-binomial-distribution">Negative binomial distribution</a></li> <li><a href="#geometric-distribution" id="markdown-toc-geometric-distribution">Geometric distribution</a></li> <li><a href="#poisson-distribution" id="markdown-toc-poisson-distribution">Poisson distribution</a></li> <li><a href="#exponential-distribution" id="markdown-toc-exponential-distribution">Exponential distribution</a></li> <li><a href="#gamma-distribution" id="markdown-toc-gamma-distribution">Gamma distribution</a></li> <li><a href="#inverse-gamma-distribution" id="markdown-toc-inverse-gamma-distribution">Inverse-gamma distribution</a></li> <li><a href="#beta-distribution" id="markdown-toc-beta-distribution">Beta distribution</a></li> <li><a href="#normal-distribution" id="markdown-toc-normal-distribution">Normal distribution</a></li> </ul> </li> </ul> <p><em>Reference:</em></p> <p>Mainly collected from Wikipedia and class notes of the class STAT 5100 in CU Boulder.</p> <h1 id="basic-knowledge">Basic knowledge</h1> <ol> <li> <p>Cumulative distribution function (<strong>CDF</strong>)</p> <p>The cumulative distribution function of a real-valued random variable \(X\) is the function given by</p> \[F_X (x) = P(X \leq x)\] <p>CDF can be find by integrating PDF.</p> </li> <li> <p>Probability density function (<strong>PDF</strong>)</p> <p>A function that defines the relationship between continuous random variables and their probabilities. If the random variables are discrete, we call it <strong>Probability mass function (PMF)</strong>.</p> \[P(X \in [a,b]) = \int_a^b f_X(x)dx\] <p>PDF can be find by differentiating CDF.</p> </li> <li> <p>Law of total probability</p> \[P(A) = \sum_n P(A \cap B_n) \text{ or } P(A) = \sum_n P(A \mid B_n) P(B_n)\] </li> <li> <p>Bayesian statistics</p> \[\text{Posterior} = \frac{\text{Likelihood} \times \text{Prior}}{\text{Evidence}}\] <p>Given a prior belief that a PDF is \(p(\theta)\) and that the observations \(x\) have a likelihood \(p(x \mid \theta )\), then the posterior probability is defined as</p> \[p(\theta \mid x) = \frac{p(x \mid \theta) p(\theta)}{p(x)}\] <p>where \(p(\theta)\) is the normalizing constant and is calculated as</p> \[p(x) = \int p(x\mid\theta) p(\theta) d(\theta)\] </li> <li> <p>Conjugate prior</p> <p>In Bayesian probability, if the <strong><em>posterior</em></strong> distribution \(p ( \theta \mid x )\) is in the same probability distribution family as the <strong><em>prior</em></strong> probability distribution \(p(\theta )\), the <strong><em>prior</em></strong> and <strong>posterior</strong> are then called <strong>conjugate distributions</strong>, and the prior is called a <strong>conjugate prior</strong> for the <strong><em>likelihood</em></strong> function \(p(x\mid \theta )\).</p> <p><a href="https://en.wikipedia.org/wiki/Conjugate_prior#Table_of_conjugate_distributions">Common conjugate distributions</a></p> </li> <li> <p>Manually calculate a p-value</p> <p>The p-value for:</p> <p>a lower-tailed test is specified by: \(\text{p-value} = P(TS \leq ts \mid H_0 \text{ is true}) = \text{cdf}(ts)\)</p> <p>an upper-tailed test is specified by: \(\text{p-value} = P(TS \geq ts \mid H_0 \text{ is true}) = 1 - \text{cdf}(ts)\)</p> <p>\(\text{TS}\) is “Test statistic”, \(\text{ts}\) is the observed value of the test statistic calculated from your sample.</p> </li> <li> <p>Distributions of Certain Sums</p> <ul> <li>A Sum of Bernoullis is Binomial</li> <li>A Sum of Binomials is Binomial</li> <li>A Sum of Poissons is Poisson</li> <li>A Sum of Geometrics is Negative Binomial</li> </ul> </li> </ol> <h1 id="common-distributions">Common distributions</h1> <h2 id="symmetric-probability-distribution">Symmetric probability distribution</h2> <p>A probability distribution is said to be symmetric if and only if there exists a value \(x_{0}\) such that</p> \[f(x_{0}-\delta )=f(x_{0}+\delta )\] <p>for all real numbers \(\delta\) , where \(f\) is the PDF if the distribution is continuous or the probability mass function if the distribution is discrete.</p> <h2 id="uniform-distribution">Uniform distribution</h2> <p>Notation: \(X \sim \mathrm{Unif}(a,b)\)</p> <p>PDF:</p> \[f(x)={\begin{cases}{\frac {1}{b-a}}&amp;\mathrm {for} \ a\leq x\leq b,\\[8pt]0&amp;\mathrm {for} \ x&lt;a\ \mathrm {or} \ x&gt;b\end{cases}}\] <figure> <img src="https://upload.wikimedia.org/wikipedia/commons/9/96/Uniform_Distribution_PDF_SVG.svg" alt="PDF of continuous uniform distribution" width="300pt"/> <figcaption>PDF of continuous uniform distribution</figcaption> </figure> <p>CDF:</p> \[f(x)={\begin{cases}0&amp;{\text{for }}x&lt;a\\[8pt]{\frac {x-a}{b-a}}&amp;{\text{for }}a\leq x\leq b\\[8pt]1&amp;{\text{for }}x&gt;b\end{cases}}\] <figure> <img src="https://upload.wikimedia.org/wikipedia/commons/6/63/Uniform_cdf.svg" alt="CDF of continuous uniform distribution" width="300pt"/> <figcaption>CDF of continuous uniform distribution</figcaption> </figure> <h2 id="bernoulli-distribution">Bernoulli distribution</h2> <p>Notation: \(Bernoulli(p)\) or \(Bern(p)\)</p> <p>Let \(X\) be a random variable that takes on the values \(1\) and \(0\) with respective probabilities \(p\) and \(1 − p\). Then \(X\) is said to have a <em>Bernoulli distribution with parameter \(p\)</em>.</p> \[{\displaystyle \Pr(X=1)=p=1-\Pr(X=0)=1-q.}\] <p>The PMF of this distribution, over possible outcomes \(x\), is</p> \[P(X=x)={ \begin{cases} p &amp;{\text{if }}x=1,\\ q=1-p &amp;{\text{if }}x=0.\end{cases}}\] <p>or</p> \[{\displaystyle P(X=x)=p^{x}(1-p)^{1-x}\quad {\text{for }}x\in \{0,1\}}\] <p>or</p> \[{\displaystyle P(X=x)=px+(1-p)(1-x)\quad {\text{for }}x\in \{0,1\}.}\] <p>The mean or expected value of the Bernoulli distribution is</p> \[E[X] = \sum_x x P (X = x) = 0 (1 − p) + 1 p = p\] \[E[X^2] = \sum_x x P (X = x) = 0^2 (1 − p) + 1^2 p = p\] <p>Then the variance of this distribution is</p> \[\text{Var}[X] = E[X^2] − (E[X])^2 = p − p^2 = p(1 − p)\] <p>The Bernoulli distribution is a special case of the <a href="#binomial-distribution">binomial distribution</a> with \(n = 1\).</p> <h2 id="binomial-distribution">Binomial distribution</h2> <p>Notation: \(B(n,p)\) or \(bin(n,p)\)</p> <p>The binomial distribution with parameters \(n\) and \(p\) is the discrete probability distribution of <em>the number of successes in a sequence of \(n\) independent experiments</em>, each asking a yes–no question, and each with its own Boolean-valued outcome: success (with probability \(p\)) or failure (with probability \(q = 1 − p\)).</p> <p>PMF:</p> \[P(X=x)={\binom {n}{x}}p^{x}(1-p)^{n-x}\] <p>for x = 0, 1, 2, …, n, where</p> \[{\displaystyle {\binom {n}{x}}={\frac {n!}{x!(n-x)!}}}\] <p>is the binomial coefficient. The formula can be understood as follows: \(x\) successes occur with probability \(p^x\) and \(n − x\) failures occur with probability \((1-p)^{n-x}\). However, the \(x\) successes can occur anywhere among the \(n\) trials, and there are \({\tbinom {n}{x}}\) different ways of distributing \(x\) successes in a sequence of \(n\) trials.</p> \[E[X] = np\] \[Var[X] = np(1 − p)\] <p>A single success/failure experiment is also called a Bernoulli trial or Bernoulli experiment, and a sequence of outcomes is called a Bernoulli process; for a single trial, i.e., \(n = 1\), the binomial distribution is a <a href="#bernoulli-distribution">Bernoulli distribution</a>.</p> <h2 id="negative-binomial-distribution">Negative binomial distribution</h2> <p>Notation: \(\mathrm {NB} (r,\,p)\) or \(negbin(r,p)\)</p> <p>\(r &gt; 0\) — number of successes until the experiment is stopped (integer, but the definition can also be extended to reals)</p> <p>\(p \in [0,1]\) — success probability in each experiment (real)</p> <p>PMF:</p> \[{\displaystyle f(x;r,p)\equiv \Pr(X=x)={\binom {x+r-1}{x}}(1-p)^{x}p^{r}}\] <h2 id="geometric-distribution">Geometric distribution</h2> <p>Notation: \(geom(p)\)</p> <p>Consider a sequence of independent trials of an experiment where each trial can result in either “Success” (\(S\)) or “Failure” (\(F\)). Let \(0 \leq p \leq 1\) be the probability of <em>success</em> on any one trial. It’s a special case of negative binomial distribution.</p> <p>Definition 1 (“number of trials” model):</p> <p>Let \(x\) be the number of trials until the first success. There will be \(x-1\) failures, each with probability \(1-p\)</p> <p>PMF:</p> \[P (X = x) = (1 − p)^{x−1} p \text{ for } x \text{ in } \{1, 2, 3, \ldots \}\] <p>Definition 2 (“number of failures” model):</p> <p>Let \(x\) be the number of failures before the first success. There will be \(x\) failures, each with probability \(1-p\).</p> <p>PMF:</p> \[P (X = x) = (1 − p)^{x} p \text{ for } x \text{ in } \{0, 1, 2, \ldots \},\] <h2 id="poisson-distribution">Poisson distribution</h2> <p>Notation \(Poisson(\lambda)\)</p> <p>A random variable \(X\) has a Poisson distribution with parameter \(\lambda &gt; 0\) if \(X\) has PDF</p> \[\begin{aligned} P (X = x) &amp;= {\begin{cases} \frac{e^{−\lambda}\lambda^x}{x!} &amp;, \quad x = 0, 1, 2, \ldots\\ 0 &amp;, \quad \text{otherwise} \end{cases}} \\ &amp;= \frac{e^{−\lambda}\lambda^x}{x!} I_{\{0,1,2,\dots\}}(x) \end{aligned}\] <h2 id="exponential-distribution">Exponential distribution</h2> <p>Notation: \(exp(\lambda)\) or \(rate=\lambda\)</p> <p>Let \(\lambda &gt; 0\) be a fixed parameter and consider the continuous random variable with PDF</p> \[\begin{aligned} P (X = x) &amp;= {\begin{cases} \lambda e^{-\lambda x} &amp;, \quad x &gt; 0\\ 0 &amp;, \quad \text{otherwise} \end{cases}} \\ &amp;= \lambda e^{-\lambda x} I_{(0,\infty)}(x) \end{aligned}\] <p>CDF:</p> \[F (x) = P (X \leq x) = \int_o^x \lambda e^{−\lambda u} du = 1 − e^{−λx}\] <p>Tail probability:</p> \[P (X &gt; x) = 1 − P (X \leq x) = 1 − F (x) = e^{−λx}.\] <h2 id="gamma-distribution">Gamma distribution</h2> <p>Notation:</p> <ul> <li>Gamma distribution \(\Gamma(\alpha, \beta)\)</li> <li>Gamma function \(\Gamma(\alpha)\)</li> </ul> <p>Gamma distribution:</p> <p>Let \(\alpha &gt; 0\) and \(\beta &gt; 0\) be fixed parameters and consider the continuous random variable with PDF</p> \[\begin{aligned} f(x) &amp;= {\begin{cases} \frac{\beta^{\alpha}}{\Gamma(\alpha)}x^{\alpha-1}e^{-\beta x} &amp;, \quad x &gt; 0\\ 0 &amp;, \quad \text{otherwise} \end{cases}} \\ &amp;= \frac{\beta^{\alpha}}{\Gamma(\alpha)}x^{\alpha-1}e^{-\beta x} I_{(0,\infty)}(x) \end{aligned}\] <p>\(\alpha\) is known as a <em>shape parameter</em> and \(\beta\) is known as an <em>inverse scale parameter</em>.</p> <p>Gamma function:</p> <p>The pdf is given in terms of the <em>gamma function</em> which is defined, for \(\alpha &gt; 0\) as \(\Gamma(\alpha) = \int_0^{\infty} x^{\alpha -1} e^{-x}dx\).</p> <p>Properties of Gamma function:</p> <ul> <li>For \(\alpha &gt;1\), \(\Gamma(\alpha) = (\alpha-1)\Gamma(\alpha-1)\)</li> <li>If \(n\geq 1\) is an integer, \(\Gamma(n) = (n-1)!\)</li> <li>(Since \(0!=1\)), \(\Gamma(1)=1\)</li> </ul> <h2 id="inverse-gamma-distribution">Inverse-gamma distribution</h2> <p>Notation: \(X \sim \mathrm{Inv}\Gamma(\alpha, \beta)\)</p> \[{\displaystyle f(x;\alpha ,\beta )={\frac {\beta ^{\alpha }}{\Gamma (\alpha )}}(\frac{1}{x})^{\alpha +1}e^{\left(-\beta \frac{1}{x}\right)}} \text{ , for } x &gt; 0\] <h2 id="beta-distribution">Beta distribution</h2> <p>Notation: \(Beta(\alpha, \beta)\)</p> <p>A family of continuous probability distributions defined on the interval \([ 0 , 1 ]\) in terms of two positive parameters, denoted by alpha (\(\alpha\)) and beta (\(\beta\)), that appear as exponents of the variable and its complement to \(1\), respectively, and control the shape of the distribution.</p> <p>Mean:</p> \[E[X] = \frac{\alpha}{\alpha + \beta}\] <p>PDF:</p> \[\begin{align*} f(p;\alpha, \beta) &amp;= \frac{(\alpha + \beta -1)!}{(\alpha -1)!(\beta-1)!} p^{\alpha-1}(1-p)^{\beta-1} \\ &amp;\propto p^{\alpha-1}(1-p)^{\beta-1} \end{align*}\] <figure> <img src="https://upload.wikimedia.org/wikipedia/commons/f/f3/Beta_distribution_pdf.svg" alt="PDF of Beta distribution" width="300pt"/> <figcaption>PDF of Beta distribution</figcaption> </figure> <p>CDF:</p> <figure> <img src="https://upload.wikimedia.org/wikipedia/commons/1/11/Beta_distribution_cdf.svg" alt="CDF of Beta distribution" width="300pt"/> <figcaption>CDF of Beta distribution</figcaption> </figure> <p>In Bayesian inference, the beta distribution is the <a href="#basic-knowledge">conjugate prior</a> probability distribution for the <a href="#bernoulli-distribution">Bernoulli</a>, <a href="#binomial-distribution">binomial</a>, <a href="#negative-binomial-distribution">negative binomial</a> and <a href="#geometric-distribution">geometric distributions</a>.</p> <h2 id="normal-distribution">Normal distribution</h2> <p>Notation: \(X \sim \mathcal{N}(\mu, \sigma^2)\)</p> <p>PDF:</p> \[{\displaystyle f(x)={\frac {1}{\sigma {\sqrt {2\pi }}}}e^{-{\frac {1}{2}}\left({\frac {x-\mu }{\sigma }}\right)^{2}}}\]]]></content><author><name></name></author><category term="Bayesian,"/><category term="Markov"/><summary type="html"><![CDATA[TOC]]></summary></entry><entry><title type="html">Poisson Flow Generative Models</title><link href="https://liguiye.github.io/blog/2022/Poisson-flow/" rel="alternate" type="text/html" title="Poisson Flow Generative Models"/><published>2022-12-28T15:59:00+00:00</published><updated>2022-12-28T15:59:00+00:00</updated><id>https://liguiye.github.io/blog/2022/Poisson-flow</id><content type="html" xml:base="https://liguiye.github.io/blog/2022/Poisson-flow/"><![CDATA[<p><em>TOC</em></p> <ul id="markdown-toc"> <li><a href="#main-idea" id="markdown-toc-main-idea">Main idea</a></li> <li><a href="#training-process" id="markdown-toc-training-process">Training process</a></li> </ul> <p><em>Reference:</em></p> <p>Official links:</p> <ol> <li> <p>PFGM (NeurIPS 2022)</p> <p>Paper: <a href="https://arxiv.org/pdf/2209.11178.pdf">Poisson Flow Generative Models</a></p> <p>Github: <a href="https://github.com/Newbeeer/poisson_flow">https://github.com/Newbeeer/poisson_flow</a></p> </li> </ol> <p>Blog:</p> <ol> <li><a href="https://www.assemblyai.com/blog/an-introduction-to-poisson-flow-generative-models/">An Introduction to Poisson Flow Generative Models</a></li> </ol> <h2 id="main-idea">Main idea</h2> <p>The idea is inspired by the field of <strong>electrodynamics</strong> that Any distribution of electrons in a hyperplane generates an electric field (aka <strong>Poisson field</strong>) that transforms the distribution into a uniform angular distribution as the distribution evolves through time according to the dynamics defines by the field.</p> <figure> <img src="https://www.assemblyai.com/blog/content/images/2022/10/PFGM_evolution-1.png" alt="The key of PFGM." width="600pt"/> <figcaption>Treating a data distribution as a charge distribution defines an electric field that transforms the distribution into a uniform hemisphere over time.</figcaption> </figure> <p>If we know the electric field (Poisson field) generated by a distribution, then we can <em>start</em> with points uniformly sampled on a hemisphere and run the dynamics in reverse time to recover the original data distribution. The <strong>law of physics</strong>, therefore, provide an invertible mapping between a simple distribution and the data distribution, yielding a means to generate novel data akin to normalizing flows.</p> <figure> <img src="https://www.assemblyai.com/blog/content/images/size/w1000/2022/10/dog_reverse_time.png" alt="The reverse process." width="600pt"/> <figcaption> Uniformly sampled points on the hemisphere can be transformed into samples from the data distribution by evolving them backwards through the Poisson field generated by the data distribution. </figcaption> </figure> <h2 id="training-process">Training process</h2> <p>We seek to model the dynamics of particles under the influence of the Poisson field generated by a data distribution.</p> <figure> <img src="https://www.assemblyai.com/blog/content/images/2022/10/PFGM.gif" alt="" width="600pt"/> <figcaption> </figcaption> </figure>]]></content><author><name></name></author><category term="generative-model"/><category term="deep-learning"/><category term="diffusion-model"/><summary type="html"><![CDATA[TOC]]></summary></entry><entry><title type="html">Diffusion models</title><link href="https://liguiye.github.io/blog/2022/Diffusion-models/" rel="alternate" type="text/html" title="Diffusion models"/><published>2022-12-14T15:59:00+00:00</published><updated>2022-12-14T15:59:00+00:00</updated><id>https://liguiye.github.io/blog/2022/Diffusion-models</id><content type="html" xml:base="https://liguiye.github.io/blog/2022/Diffusion-models/"><![CDATA[<p><em>TOC</em></p> <ul id="markdown-toc"> <li><a href="#background-information" id="markdown-toc-background-information">Background information</a> <ul> <li><a href="#markov-chain" id="markdown-toc-markov-chain">Markov chain</a></li> <li><a href="#reparameterization-trick" id="markdown-toc-reparameterization-trick">Reparameterization trick</a></li> </ul> </li> <li><a href="#main-idea-of-diffusion-model" id="markdown-toc-main-idea-of-diffusion-model">Main idea of Diffusion Model</a> <ul> <li><a href="#forward-process-or-diffusion-process" id="markdown-toc-forward-process-or-diffusion-process"><em>Forward process</em> (or <em>diffusion process</em>)</a></li> <li><a href="#reverse-process-or-reverse-diffusion-process" id="markdown-toc-reverse-process-or-reverse-diffusion-process"><em>Reverse process</em> (or <em>reverse diffusion process</em>)</a></li> </ul> </li> <li><a href="#benefits-of-diffusion-models" id="markdown-toc-benefits-of-diffusion-models">Benefits of Diffusion Models</a></li> <li><a href="#training" id="markdown-toc-training">Training</a></li> <li><a href="#summary" id="markdown-toc-summary">Summary</a></li> </ul> <p><em>Reference:</em></p> <p>Official links:</p> <ol> <li> <p>DDPM (NeurIPS 2020)</p> <p>Paper: <a href="https://arxiv.org/abs/2006.11239">Denoising Diffusion Probabilistic Models</a></p> <p>Github: <a href="https://github.com/hojonathanho/diffusion">https://github.com/hojonathanho/diffusion</a></p> <p>Website: <a href="https://hojonathanho.github.io/diffusion/">https://hojonathanho.github.io/diffusion/</a></p> </li> <li> <p>Improved DDPM (ICML 2021)</p> <p>Paper: <a href="https://arxiv.org/abs/2102.09672">Improved Denoising Diffusion Probabilistic Models</a></p> <p>Github: <a href="https://github.com/openai/improved-diffusion">https://github.com/openai/improved-diffusion</a></p> </li> <li> <p>Guided Diffusion Models (NeurIPS 2021)</p> <p>Paper: <a href="https://arxiv.org/pdf/2105.05233.pdf">Diffusion Models Beat GANs on Image Synthesis</a></p> <p>Github: <a href="https://github.com/openai/guided-diffusion">https://github.com/openai/guided-diffusion</a></p> </li> </ol> <p>Blog:</p> <ol> <li><a href="https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/">Introduction to Diffusion Models for Machine Learning</a></li> <li><a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/">What are Diffusion Models?</a></li> </ol> <h2 id="background-information">Background information</h2> <h3 id="markov-chain">Markov chain</h3> <p>Quote from <a href="https://en.wikipedia.org/wiki/Markov_chain#:~:text=A%20Markov%20chain%20or%20Markov,the%20state%20of%20affairs%20now.%22">Wikipedia</a>:</p> <p>A <strong>Markov chain</strong> or <strong>Markov process</strong> is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. Informally, this may be thought of as, “What happens next depends only on the state of affairs now”.</p> <h3 id="reparameterization-trick">Reparameterization trick</h3> <p>The role of reparameterization trick (from VAE) is to make a stochastic sampling process trainable. Assuming a sampling process from \(\mathbf{z} \sim q_ \phi(\mathbf{z}\vert\mathbf{x})\). To express the random variable \(\mathbf{z}\) as a deterministic variable \(\mathbf{z} = \mathcal{T}_ \phi (\mathbf{x}, \mathbf{\epsilon} )\), where \(\mathbf{\epsilon}\) is an suxiliary independent random variable, and the transformation function \(\mathcal{T}_ \phi\) parameterized by \(\phi\) converts \(\mathbf{\epsilon}\) to \(\mathbf{z}\).</p> <p>For example, a common choice of the form of \(q_ \phi (z \vert x)\) is a multivariate Gaussian distribution with a diagonal covariance structure:</p> <p>\begin{equation} \mathbf{z} \sim q_\phi(\mathbf{z}\vert\mathbf{x}^{(i)}) = \mathcal{N}(\mathbf{z}; \boldsymbol{\mu}^{(i)}, \boldsymbol{\sigma}^{2(i)}\boldsymbol{I}) \end{equation}</p> <p>Applying the reparameterization trick:</p> <p>\begin{equation} \mathbf{z} = \boldsymbol{\mu} + \boldsymbol{\sigma} \odot \boldsymbol{\epsilon} \quad \text{where} \quad \boldsymbol{\epsilon} \sim \mathcal{N}(0, \boldsymbol{I}) \end{equation}</p> <p>Tips:</p> <ol> <li>\(\odot\) refers to element-wise product.</li> <li>\(q_ \phi (\mathbf{z} \vert \mathbf{x})\) stands for a estimated posterior probability function, aso known as <strong>probabilistic encoder</strong>.</li> <li>\(p_{\theta}(\mathbf{x}\vert\mathbf{z})\) is the likelihood of generating true data sample given the latent code, also known as <strong>probabilistic decoder</strong>.</li> </ol> <h2 id="main-idea-of-diffusion-model">Main idea of Diffusion Model</h2> <p>Diffusion models works by <strong>destroying training data</strong> through the successive addition if Gaussian noise, and then <strong>learning to recover</strong> the data by reversing this noising process. It draws inspiration from physics, in particular <strong>thermodynamics</strong>/statistical physics. After training, we can use the Diffusion Model to generate data by simply <strong>passing randomly sampled noise through the learned denoising process</strong>.</p> <h3 id="forward-process-or-diffusion-process"><em>Forward process</em> (or <em>diffusion process</em>)</h3> <p>Specifically, a Diffusion Model is a latent variable model which maps to the latent space using a fixed Markov chain. This chain gradually adds noise to the data in order to obtain the <strong>approximate posterior</strong> \(q(\mathbf{x}_{1:T}\vert \mathbf{x}_0)\), where \(\mathbf{x}_1,\ldots,\mathbf{x}_T\) are the latent variables (a sequence of noisy samples) with the same dimensionality as \(\mathbf{x}_0\). See figure below.</p> <figure> <img src="https://www.assemblyai.com/blog/content/images/size/w1000/2022/05/image.png" alt="The Markov chain manifested for image data." width="600pt"/> <figcaption>Forward process.</figcaption> </figure> <p>A parameterization of the forward process (combing Markov assumption):</p> <p>\begin{equation} \label{eq:forward-process} q(\mathbf{x}_ t \vert \mathbf{x}_ {t-1}) = \mathcal{N}(\mathbf{x}_ t; \sqrt{1 - \beta_ t} \mathbf{x}_ {t-1}, \beta_ t\mathbf{I}) \quad q(\mathbf{x}_ {1:T} \vert \mathbf{x}_ 0) = \prod^T_{t=1} q(\mathbf{x}_ t \vert \mathbf{x}_ {t-1}) \end{equation}</p> <p>where \(\{\beta_t \in (0, 1)\}_{t=1}^T\) is a variance schedule (either learned or fixed) controlling the step sizes which, if well-behaved, <strong>ensures that \(\mathbf{x}_T\) is nearly an isotropic Gaussian for sufficiently large \(T\)</strong>. In other words, the data sample \(\mathbf{x}_0\) gradually loss its distinguishable features as the step \(t\) becomes larger. Eventually, when \(T \to \infty\), \(\textbf{x}_T\) is equivalent to an isotropic Gaussian distribution.</p> <p>We can sample \(\mathbf{x}_t\) at any arbitrary time step \(t\) in a closed form using <a href="#reparameterization-trick">reparameterization trick</a>.</p> <p>Given</p> \[\begin{aligned} q(\mathbf{x}_ t \vert \mathbf{x}_ {t-1}) = \mathcal{N}(\mathbf{x}_ t; \sqrt{1 - \beta_ t} \mathbf{x}_ {t-1}, \beta_ t\mathbf{I}) \end{aligned}\] <p>Let \(\alpha_t = 1 - \beta_ t \text{ and } \bar{\alpha}_t = \prod_{i=1}^t \alpha_i\) :</p> \[\begin{aligned} \mathbf{x}_ t &amp;= \sqrt{1 - \beta_ t} \mathbf{x}_ {t-1} + \sqrt{\beta_ t} \epsilon_ {t-1} \quad \text{, where } {\epsilon_ t \sim \mathcal{N}(\mathbf{0},\mathbf{I})}_ {t=0}^{t-1} \\ &amp;= \sqrt{\alpha_t} \mathbf{x}_ {t-1} + \sqrt{1-\alpha_ t} \epsilon_ {t-1} \\ &amp;= \sqrt{\alpha_t \alpha_{t-1}} \mathbf{x}_{t-2} + \sqrt{1 - \alpha_t \alpha_{t-1}} \bar{\boldsymbol{\epsilon}}_{t-2} \quad \text{, where } \bar{\boldsymbol{\epsilon}}_{t-2} \text{ merges two Gaussian distributions.} \\ &amp;= \dots \\ &amp;= \sqrt{\bar{\alpha_t}} \mathbf{x}_0 + \sqrt{1-\bar{\alpha_t}} \epsilon \end{aligned}\] <p>Hence</p> \[\begin{aligned} q(\mathbf{x}_ t \vert \mathbf{x}_0) = \mathcal{N}(\mathbf{x}_ t; \sqrt{\bar{\alpha_t}} \mathbf{x}_0, (\sqrt{1-\bar{\alpha_t}})\mathbf{I}) \end{aligned}\] <p>Tips:</p> <ol> <li>If we merge two Gaussian distributions with different variance, \(\mathcal{N}(\mathbf{0}, \sigma^2_ 1 \mathbf{I})\) and \(\mathcal{N}(\mathbf{0}, \sigma^2_ 2 \mathbf{I})\), the new distribution is \(\mathcal{N}(\mathbf{0}, (\sigma^2_ 1 + \sigma^2_ 2) \mathbf{I})\).</li> </ol> <h3 id="reverse-process-or-reverse-diffusion-process"><em>Reverse process</em> (or <em>reverse diffusion process</em>)</h3> <p>Ultimately, the image is asymptotically transformed to pure Gaussian noise. The goal of training a diffusion model is to <strong>learn the reverse process</strong>, i.e. training \(p_\theta (X_{t-1} \vert X_t)\). See figure below, by traversing backwards along this chain, we can generate new data.</p> <figure> <img src="https://www.assemblyai.com/blog/content/images/size/w1000/2022/05/image-1.png" alt="The reverse process of the Markov chain." width="600pt"/> <figcaption>Reverse process.</figcaption> </figure> <p>Starting with the pure Gaussian noise \(p(X_T)=\mathcal{N}(X_T;\mathbf{0},\mathbf{I})\), the model learns the joint distribution \(p_\theta(X_0;T)\) as:</p> <p>\begin{equation} p_ \theta ( \mathbf{x}_ {t-1} \vert \mathbf{x}_ t) = \mathcal{N} ( \mathbf{x}_ {t-1}; \boldsymbol{\mu}_ \theta ( \mathbf{x}_ t, t ) , \boldsymbol{\Sigma}_ \theta ( \mathbf{x}_ t, t ) ) \quad p_ \theta ( \mathbf{x}_ {0:T} ) = p ( \mathbf{x}_ T ) \prod^T_ {t=1} p_ \theta ( \mathbf{x}_ {t-1} \vert \mathbf{x}_ t ) \end{equation}</p> <p>where the time-dependent parameters of the Gaussian transitions are learned.</p> <h2 id="benefits-of-diffusion-models">Benefits of Diffusion Models</h2> <ol> <li>Diffusion Models currently produce State-of-the-Art image quality.</li> <li>Not requiring adversarial training.</li> <li>Scalability and parallelizability.</li> </ol> <h2 id="training">Training</h2> <p>A Diffusion Model is trained by <strong>finding the reverse Markov transitions that maximize the likelihood of the training data</strong>. The combination of \(p\) and \(q\) is a variational auto-encoder. In practice, training equivalently consists of minimizing the variational upper bound on the negative log likelihood.</p> <p>\begin{equation} \mathbb{E} [- \log p_\theta (\mathbf{x}_ 0)] \leqslant \mathbb{E}_ {q} [-\log \frac{p_ \theta (\mathbf{x}_ {0:T})}{q(\mathbf{x}_ {1:T} \vert \mathbf{x}_ 0)}] =: L_{vlb} \end{equation}</p> <p>Variational lower bound (\(L_{vlb}\)) is technically an upper bound (the negative of the Evidence Lower Bound (ELBO)) which we are trying to minimize. We will try to rewrite the \(L_{vlb}\) in terms of Kullback-Leibler (KL) Divergences because the transition distributions in the Markov chain are Gaussians, and <strong>the KL divergence between Gaussians has a closed form</strong>.</p> <p>\begin{equation} D_{KL}(P\parallel Q) = \int_{-\infty}^{\infty} p(x)\log(\frac{p(x)}{q(x)}) dx \end{equation}</p> <p>Casting \(L_{vlb}\) in terms of KL Divergences</p> <p>\begin{equation} L_{vlb} = L_0 + L_1 + \ldots + L_{T-1} + L_T \end{equation}</p> <p>where</p> \[\begin{aligned} L_0 &amp;= -\log p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1) \\ L_t &amp;= D_{KL}(q(\mathbf{x}_t \vert \mathbf{x}_ {t+1} , \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_ t \vert \mathbf{x}_ {t+1})) \quad \text{ for } 1 \leq t \leq T-1\\ L_T &amp;= D_{KL}(q(\mathbf{x}_T \vert \mathbf{x}_0) \parallel p_\theta (\mathbf{x}_T)) \end{aligned}\] <p>Conditioning the forward process posterior on \(\mathbf{x}_0\) in \(L_{t-1}\) results in a tractable form that leads to <strong>all KL divergences being comparisons between Gaussians</strong>. This means that the divergences can be exactly calculated with closed-form expressions rather than with Monte Carlo estimates.</p> <h2 id="summary">Summary</h2> <ol> <li>Diffusion Models are <strong>highly flexible</strong> and allow for any architecture whose input and output dimensionality are the same to be used. Many implementations use <strong>U-Net-like</strong> architectures.</li> <li>The <strong>training objective</strong> is to maximize the likelihood of t he training data. This is manifested as tuning the model parameters to <strong>minimize the variational upper bound of the negative log likelihood of the data</strong>.</li> <li>Almost all terms in the objective function can be cast as <strong>KL Divergences</strong> as a result of the Markov assumption. This values <strong>become tenable to calculated</strong> given that we are using Gaussians, therefore omitting the need to perform MonteCarlo approximation.</li> <li>A discrete decoder is used to obatin log likelihoods across pixel values as the last step in the reverse diffusion process.</li> </ol>]]></content><author><name></name></author><category term="generative-model"/><category term="deep-learning"/><category term="diffusion-model"/><summary type="html"><![CDATA[TOC]]></summary></entry><entry><title type="html">Score based methods</title><link href="https://liguiye.github.io/blog/2022/Score-based-methods/" rel="alternate" type="text/html" title="Score based methods"/><published>2022-12-13T15:59:00+00:00</published><updated>2022-12-13T15:59:00+00:00</updated><id>https://liguiye.github.io/blog/2022/Score-based-methods</id><content type="html" xml:base="https://liguiye.github.io/blog/2022/Score-based-methods/"><![CDATA[<p><em>TOC</em></p> <ul id="markdown-toc"> <li><a href="#1-score-based-generative-modeling" id="markdown-toc-1-score-based-generative-modeling">1. Score-based generative modeling</a> <ul> <li><a href="#score-matching-for-score-estimation" id="markdown-toc-score-matching-for-score-estimation">score matching for score estimation</a> <ul> <li><a href="#11-denoising-score-matching" id="markdown-toc-11-denoising-score-matching">1.1. Denoising score matching</a></li> <li><a href="#12-sliced-score-matching" id="markdown-toc-12-sliced-score-matching">1.2. Sliced score matching</a></li> </ul> </li> </ul> </li> <li><a href="#2-sampling-with-langevin-dynamics" id="markdown-toc-2-sampling-with-langevin-dynamics">2. Sampling with Langevin Dynamics</a></li> <li><a href="#3-challenges" id="markdown-toc-3-challenges">3. Challenges</a></li> <li><a href="#4-contributions-of-ncsn" id="markdown-toc-4-contributions-of-ncsn">4. Contributions of NCSN</a></li> </ul> <p><em>Reference:</em></p> <p>Official links:</p> <p>Noise Conditional Score Networks (NCSN) (NeurIPS 2019)</p> <ol> <li>Paper: <a href="https://arxiv.org/abs/1907.05600">Generative Modeling by Estimating Gradients of the Data Distribution</a></li> <li>Blog: <a href="https://yang-song.net/blog/">https://yang-song.net/blog/</a></li> <li>Github: <a href="https://github.com/ermongroup/ncsn">https://github.com/ermongroup/ncsn</a></li> </ol> <h2 id="1-score-based-generative-modeling">1. Score-based generative modeling</h2> <p>Given a probability density function (PDF) \(p(x)\), the ‘score’ is defined as \(\triangledown_x \log p(x)\), or the gradient of the log-likelihood of the object \(x\) w.r.t the input dimensions \(x\), notably not w.r.t the model parameters \(\theta\). We will assume that PDFs are continuous random variables. The score is a vector field of the gradient at any point \(x\). This gradient of \(\log p(x)\) tells us the directions in which to move if we want to increase the likelihood as much as possible.</p> <p>The <strong>score-based network</strong> \(s_\theta: \mathbb{R}^D \rightarrow \mathbb{R}^D\) is a neural network parameterized by \(\theta\), which will be trained to approximate the score of \(p_ {data}(x)\) ( \(\triangledown_x\log p(x)\) ). The framework of score-based generative modeling has two ingredients: <em>score matching</em> and <em>Langevin dynamics</em>.</p> <h3 id="score-matching-for-score-estimation">score matching for score estimation</h3> <p>Using score matching, we can directly train a score network \(s_\theta(x)\) to estimate \(\triangledown_x \log p(x)\) without training a model to estimate \(p_ {data}(x)\) first.</p> <p>The objective minimizes \(\frac{1}{2} \mathbb{E}_ {p_ {data}(x)}[\parallel s_\theta(x)-\triangledown_x \log p_ {data}(x)\parallel_2^2]\), which can be shown equivalent to the following up to a constant</p> <p>\begin{equation} \mathbb{E}_ {p_ {data}(x)}[\text{tr}(\triangledown_xs_\theta(x))+\frac{1}{2}\parallel s_\theta(x)\parallel _2^2] \end{equation}</p> <p>where \(\triangledown_xs_\theta(x)\) is the Jacobian (first-order partial derivatives) of \(s_\theta(x)\). Note that the trace of a square matrix \(A\), denoted \(\text{tr}(A)\), is defined to be the sum of elements on the main diagonal (from the upper left to the lower right) of \(A\).</p> <p>In practice, the expectation over \(p_ {data}(x)\) can be quickly estimated using data samples. However, score matching is not scalable to deep networks and high dimensional data due to the computation of \(\text{tr}(\triangledown_xs_\theta(x))\). Below are the two popular methods for large scale score matching.</p> <h4 id="11-denoising-score-matching">1.1. Denoising score matching</h4> <p>A variant of score matching that completely circumvents \(\text{tr}(\triangledown_xs_\theta(x))\). It first perturbs the data point \(x\) with a pre-specified noise distribution \(q_\sigma(\tilde{x}\vert x)\) and then employs score matching to estimate the score of the perturbed data distribution \(q_\sigma(\tilde{x}) \triangleq \int q_\sigma(\tilde{x}\vert x)p_ {data}(x)dx\). The objective was proved equivalent to the following:</p> <p>\begin{equation} \frac{1}{2} \mathbb{E}_ {q_\sigma(\tilde{x}\vert x)p_ {data}(x)}[\parallel s_\theta(\tilde{x})-\triangledown_ {\tilde{x}}\log q_\sigma(\tilde{x}\vert x)\parallel _2^2] \end{equation}</p> <h4 id="12-sliced-score-matching">1.2. Sliced score matching</h4> <p>Sliced score matching uses random projections to approximate \(\text{tr}(\triangledown_xs_\theta(x))\) in score matching. The objective is</p> <p>\begin{equation} \mathbb{E}_ {p_v}\mathbb{E}_ {p_ {data}}[v^T \triangledown_x s_\theta(x)v + \frac{1}{2} \parallel s_\theta(x)\parallel _2^2] \end{equation}</p> <p>where \(p_v\) is a simple distribution of random vectors, e.g., the multivariate standard normal. The term \(v^T \triangledown_x s_\theta(x)v\) can be efficiently computed by forward mode auto-differentiation. Unlike denoising score matching which estimates the scores of <em>perturbed</em> data, sliced score matching provides score estimation for the original <em>unperturbed</em> data distribution, but requires around four times more computation due to the forward mode auto-differentiation.</p> <h2 id="2-sampling-with-langevin-dynamics">2. Sampling with Langevin Dynamics</h2> <p>Langevin Monte Carlo is a Markov Chain Monte Carlo (MCMC) method for obtaining random samples from probability distributions for which direct sampling is difficult. The goal is to “follow the gradient but add a bit of noise” so as to not get stuck at the local optima regions and thus we are able to explore the distribution and sample from it. It approximately works by gradually moving a random initial sample to high density regions along the (estimated) vector field of scores.</p> <p>Langevin dynamics can produce samples from a probability density \(p(x)\) using only the score function \(\triangledown_x \log p_ {data}(x)\). Given a fixed step size \(\epsilon &gt; 0\), and an initial value \(\tilde{x}_0 \sim \pi(x)\) with \(\pi\) being a prior distribution, the Langevin method recursively computes the following</p> <p>\begin{equation} \tilde{x}_ t = \tilde{x}_ {t-1} + \frac{\epsilon}{2} \triangledown_x \log p(\tilde{x}_ {t-1}) + \sqrt{\epsilon} z_t \end{equation}</p> <p>where \(z_t \sim \mathcal{N}(0,I)\). The distribution of \(\tilde{x}_T\) equals \(p(x)\) when \(\epsilon \rightarrow 0\) and \(T \rightarrow \infty\), in which case \(\tilde{x}_T\) becomes an exact sample from \(p(x)\) under some regularity conditions. We usually assume the error is negligible when \(\epsilon\) is small and \(T\) is large.</p> <hr/> <p>Note that sampling from this equation only requires the score function \(\triangledown_x \log p_ {data}(x)\). Therefore, in order to obtain samples from \(p_ {data}(x)\), we can first train our score network such that \(s_\theta(x) \approx \triangledown_x \log p_ {data}(x)\) and then approximately obtain samples with Langevin dynamics using \(s_\theta(x)\). This is the key idea of the <em>score-based generative modeling</em>.</p> <hr/> <h2 id="3-challenges">3. Challenges</h2> <ol> <li>If the <strong>data distribution is</strong> supported on a <strong>low dimensional manifold</strong> - it is often assumed for many real world datasets - the <strong>score will be undefined in the ambient space</strong>, and <strong>score matching will fail to provide a consistent score estimator</strong>. The score matching objective provides a consistent score estimator only when the support of the data distribution is the whole space.</li> <li> <p>The scarcity of training data in <strong>low data density regions</strong>, e.g., far from the manifold, <strong>hinders the accuracy of score estimation</strong> and <strong>slows down the mixing of Langevin dynamics sampling</strong>. Since Langevin dynamics will often be initialized in low-density regions of the data distribution, inaccurate score estimation in these regions will negatively affect the sampling process.</p> <p align="center" id="negative-effect-low-density"> <img src="../../../assets/img/blog/NCSN-negative_effect_of_low_density.png" alt="Inaccurate score estimation with score matching" width="300pt"/> <img src="../../../assets/img/blog/NCSN-low_density_pitfalls.jpg" alt="Inaccurate score estimation with score matching" width="600pt"/> </p> <p>As the <a href="#negative-effect-low-density">figure</a> demonstrates, score estimation is only reliable in the immediate vicinity of the models of \(p_ {data}\), where the data density is high.</p> </li> <li> <p>Mixing can be difficult because of the need of traversing low density regions to transition between models of the distribution. In other words, when two models of the data distribution are separated by low density regions, Langevin dynamics will not be able to correctly recover the relative weights of these two modes in reasonable time, and therefore might not converge to the true distribution.</p> <p align="center"> <img src="../../../assets/img/blog/NCSN-slow_mixing_of_Langevin_dynamics.png" alt="Slow mixing of Langevin dynamics" width="600pt"/> </p> </li> </ol> <h2 id="4-contributions-of-ncsn">4. Contributions of NCSN</h2> <ol> <li> <p>Propose to <strong>perturb the data with random Gaussian noise of various magnitudes</strong>.</p> <p>Adding random noise ensues the resulting distribution does not collapse to a low dimensional manifold. Large noise levels will produce samples in low density regions of the original (unperturbed) data distribution, thus improving score estimation.</p> <p align="center" id="perturb_data_with_noise"> <img src="../../../assets/img/blog/NCSN-perturb_data_with_noise.png" alt="Perturb data with random Gaussian noise" width="400pt"/> </p> <p>As the <a href="#perturb_data_with_noise">figure</a> (left) shows, when trained on the original CIFAR-10 images, the sliced score matching loss first decreases and then fluctuates irregularly. In contrast, if wee perturb the data with a small Gaussian noise (such that the perturbed data distribution has full support over \(\mathbb{R}^D\)), the loss curve will converge (right panel). Note that the Gaussian noise \(\mathcal{N}(0, 0.0001)\) we impose is very small for images with pixel values in the range \([0,1]\), and is almost indistinguishable to human eyes.</p> </li> <li> <p>Train a single score network conditioned on the noise level and estimate the scores at all noise magnitudes.</p> <p>Let \(\{ \sigma_i \}_ {i=1}^L\) be a positive geometric sequence that satisfies \(\frac{\sigma_1}{\sigma_2} = \ldots = \frac{\sigma_ {L-1}}{\sigma_L} &gt; 1\).</p> <p>Let \(q_\sigma(x) \triangleq \int p_ {data}(t) \mathcal{N}(x\vert t,\sigma^2I)dt\) denote the perturbed data distribution.</p> <p>We choose the noise levels \(\{\sigma_i\}_ {i=1}^L\) such that \(\sigma_1\) is large enough to mitigate the difficulties discussed before, and \(\sigma_L\) is small enough to minimize the effect on data. The conditional score network \(s_\theta(x,\sigma)\) is trained to jointly estimate the scores of all perturbed data distributions, i.e., \(\forall_\sigma \in \{\sigma_i\}_ {i=1}^L : s_\theta(x,\sigma) \approx \triangledown_x \log q_\sigma (x)\). Note that \(s_\theta(x,\sigma) \in \mathbb{R}^D\) when \(x \in \mathbb{R}^D\).</p> </li> <li> <p>Propose <strong>an annealed version of Langevin dynamics</strong>, where we initially use scores corresponding to the highest noise level, and gradually anneal down the noise level until it is small enough to be indistinguishable from the original data distribution.</p> </li> </ol>]]></content><author><name></name></author><category term="generative-model"/><category term="deep-learning"/><summary type="html"><![CDATA[TOC]]></summary></entry><entry><title type="html">a post with redirect</title><link href="https://liguiye.github.io/blog/2022/redirect/" rel="alternate" type="text/html" title="a post with redirect"/><published>2022-02-01T17:39:00+00:00</published><updated>2022-02-01T17:39:00+00:00</updated><id>https://liguiye.github.io/blog/2022/redirect</id><content type="html" xml:base="https://liguiye.github.io/blog/2022/redirect/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[you can also redirect to assets like pdf]]></summary></entry><entry><title type="html">a distill-style blog post</title><link href="https://liguiye.github.io/blog/2021/distill/" rel="alternate" type="text/html" title="a distill-style blog post"/><published>2021-05-22T00:00:00+00:00</published><updated>2021-05-22T00:00:00+00:00</updated><id>https://liguiye.github.io/blog/2021/distill</id><content type="html" xml:base="https://liguiye.github.io/blog/2021/distill/"><![CDATA[<h2 id="equations">Equations</h2> <p>This theme supports rendering beautiful math in inline and display modes using <a href="https://www.mathjax.org/">MathJax 3</a> engine. You just need to surround your math expression with <code class="language-plaintext highlighter-rouge">$$</code>, like <code class="language-plaintext highlighter-rouge">$$ E = mc^2 $$</code>. If you leave it inside a paragraph, it will produce an inline expression, just like \(E = mc^2\).</p> <p>To use display mode, again surround your expression with <code class="language-plaintext highlighter-rouge">$$</code> and place it as a separate paragraph. Here is an example:</p> \[\left( \sum_{k=1}^n a_k b_k \right)^2 \leq \left( \sum_{k=1}^n a_k^2 \right) \left( \sum_{k=1}^n b_k^2 \right)\] <p>Note that MathJax 3 is <a href="https://docs.mathjax.org/en/latest/upgrading/whats-new-3.0.html">a major re-write of MathJax</a> that brought a significant improvement to the loading and rendering speed, which is now <a href="http://www.intmath.com/cg5/katex-mathjax-comparison.php">on par with KaTeX</a>.</p> <hr/> <h2 id="citations">Citations</h2> <p>Citations are then used in the article body with the <code class="language-plaintext highlighter-rouge">&lt;d-cite&gt;</code> tag. The key attribute is a reference to the id provided in the bibliography. The key attribute can take multiple ids, separated by commas.</p> <p>The citation is presented inline like this: <d-cite key="gregor2015draw"></d-cite> (a number that displays more information on hover). If you have an appendix, a bibliography is automatically created and populated in it.</p> <p>Distill chose a numerical inline citation style to improve readability of citation dense articles and because many of the benefits of longer citations are obviated by displaying more information on hover. However, we consider it good style to mention author last names if you discuss something at length and it fits into the flow well — the authors are human and it’s nice for them to have the community associate them with their work.</p> <hr/> <h2 id="footnotes">Footnotes</h2> <p>Just wrap the text you would like to show up in a footnote in a <code class="language-plaintext highlighter-rouge">&lt;d-footnote&gt;</code> tag. The number of the footnote will be automatically generated.<d-footnote>This will become a hoverable footnote.</d-footnote></p> <hr/> <h2 id="code-blocks">Code Blocks</h2> <p>Syntax highlighting is provided within <code class="language-plaintext highlighter-rouge">&lt;d-code&gt;</code> tags. An example of inline code snippets: <code class="language-plaintext highlighter-rouge">&lt;d-code language="html"&gt;let x = 10;&lt;/d-code&gt;</code>. For larger blocks of code, add a <code class="language-plaintext highlighter-rouge">block</code> attribute:</p> <d-code block="" language="javascript"> var x = 25; function(x) { return x * x; } </d-code> <p><strong>Note:</strong> <code class="language-plaintext highlighter-rouge">&lt;d-code&gt;</code> blocks do not look good in the dark mode. You can always use the default code-highlight using the <code class="language-plaintext highlighter-rouge">highlight</code> liquid tag:</p> <figure class="highlight"><pre><code class="language-javascript" data-lang="javascript"><span class="kd">var</span> <span class="nx">x</span> <span class="o">=</span> <span class="mi">25</span><span class="p">;</span>
<span class="kd">function</span><span class="p">(</span><span class="nx">x</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="nx">x</span> <span class="o">*</span> <span class="nx">x</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure> <hr/> <h2 id="layouts">Layouts</h2> <p>The main text column is referred to as the body. It is the assumed layout of any direct descendants of the <code class="language-plaintext highlighter-rouge">d-article</code> element.</p> <div class="fake-img l-body"> <p>.l-body</p> </div> <p>For images you want to display a little larger, try <code class="language-plaintext highlighter-rouge">.l-page</code>:</p> <div class="fake-img l-page"> <p>.l-page</p> </div> <p>All of these have an outset variant if you want to poke out from the body text a little bit. For instance:</p> <div class="fake-img l-body-outset"> <p>.l-body-outset</p> </div> <div class="fake-img l-page-outset"> <p>.l-page-outset</p> </div> <p>Occasionally you’ll want to use the full browser width. For this, use <code class="language-plaintext highlighter-rouge">.l-screen</code>. You can also inset the element a little from the edge of the browser by using the inset variant.</p> <div class="fake-img l-screen"> <p>.l-screen</p> </div> <div class="fake-img l-screen-inset"> <p>.l-screen-inset</p> </div> <p>The final layout is for marginalia, asides, and footnotes. It does not interrupt the normal flow of <code class="language-plaintext highlighter-rouge">.l-body</code> sized text except on mobile screen sizes.</p> <div class="fake-img l-gutter"> <p>.l-gutter</p> </div> <hr/> <h2 id="other-typography">Other Typography?</h2> <p>Emphasis, aka italics, with <em>asterisks</em> (<code class="language-plaintext highlighter-rouge">*asterisks*</code>) or <em>underscores</em> (<code class="language-plaintext highlighter-rouge">_underscores_</code>).</p> <p>Strong emphasis, aka bold, with <strong>asterisks</strong> or <strong>underscores</strong>.</p> <p>Combined emphasis with <strong>asterisks and <em>underscores</em></strong>.</p> <p>Strikethrough uses two tildes. <del>Scratch this.</del></p> <ol> <li>First ordered list item</li> <li>Another item ⋅⋅* Unordered sub-list.</li> <li>Actual numbers don’t matter, just that it’s a number ⋅⋅1. Ordered sub-list</li> <li>And another item.</li> </ol> <p>⋅⋅⋅You can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we’ll use three here to also align the raw Markdown).</p> <p>⋅⋅⋅To have a line break without a paragraph, you will need to use two trailing spaces.⋅⋅ ⋅⋅⋅Note that this line is separate, but within the same paragraph.⋅⋅ ⋅⋅⋅(This is contrary to the typical GFM line break behaviour, where trailing spaces are not required.)</p> <ul> <li>Unordered list can use asterisks</li> <li>Or minuses</li> <li>Or pluses</li> </ul> <p><a href="https://www.google.com">I’m an inline-style link</a></p> <p><a href="https://www.google.com" title="Google's Homepage">I’m an inline-style link with title</a></p> <p><a href="https://www.mozilla.org">I’m a reference-style link</a></p> <p><a href="../blob/master/LICENSE">I’m a relative reference to a repository file</a></p> <p><a href="http://slashdot.org">You can use numbers for reference-style link definitions</a></p> <p>Or leave it empty and use the <a href="http://www.reddit.com">link text itself</a>.</p> <p>URLs and URLs in angle brackets will automatically get turned into links. http://www.example.com or <a href="http://www.example.com">http://www.example.com</a> and sometimes example.com (but not on Github, for example).</p> <p>Some text to show that the reference links can follow later.</p> <p>Here’s our logo (hover to see the title text):</p> <p>Inline-style: <img src="https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png" alt="alt text" title="Logo Title Text 1"/></p> <p>Reference-style: <img src="https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png" alt="alt text" title="Logo Title Text 2"/></p> <p>Inline <code class="language-plaintext highlighter-rouge">code</code> has <code class="language-plaintext highlighter-rouge">back-ticks around</code> it.</p> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">var</span> <span class="nx">s</span> <span class="o">=</span> <span class="dl">"</span><span class="s2">JavaScript syntax highlighting</span><span class="dl">"</span><span class="p">;</span>
<span class="nf">alert</span><span class="p">(</span><span class="nx">s</span><span class="p">);</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">s</span> <span class="o">=</span> <span class="s">"Python syntax highlighting"</span>
<span class="k">print</span> <span class="n">s</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>No language indicated, so no syntax highlighting.
But let's throw in a &lt;b&gt;tag&lt;/b&gt;.
</code></pre></div></div> <p>Colons can be used to align columns.</p> <table> <thead> <tr> <th>Tables</th> <th style="text-align: center">Are</th> <th style="text-align: right">Cool</th> </tr> </thead> <tbody> <tr> <td>col 3 is</td> <td style="text-align: center">right-aligned</td> <td style="text-align: right">$1600</td> </tr> <tr> <td>col 2 is</td> <td style="text-align: center">centered</td> <td style="text-align: right">$12</td> </tr> <tr> <td>zebra stripes</td> <td style="text-align: center">are neat</td> <td style="text-align: right">$1</td> </tr> </tbody> </table> <p>There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don’t need to make the raw Markdown line up prettily. You can also use inline Markdown.</p> <table> <thead> <tr> <th>Markdown</th> <th>Less</th> <th>Pretty</th> </tr> </thead> <tbody> <tr> <td><em>Still</em></td> <td><code class="language-plaintext highlighter-rouge">renders</code></td> <td><strong>nicely</strong></td> </tr> <tr> <td>1</td> <td>2</td> <td>3</td> </tr> </tbody> </table> <blockquote> <p>Blockquotes are very handy in email to emulate reply text. This line is part of the same quote.</p> </blockquote> <p>Quote break.</p> <blockquote> <p>This is a very long line that will still be quoted properly when it wraps. Oh boy let’s keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can <em>put</em> <strong>Markdown</strong> into a blockquote.</p> </blockquote> <p>Here’s a line for us to start with.</p> <p>This line is separated from the one above by two newlines, so it will be a <em>separate paragraph</em>.</p> <p>This line is also a separate paragraph, but… This line is only separated by a single newline, so it’s a separate line in the <em>same paragraph</em>.</p>]]></content><author><name>Albert Einstein</name></author><summary type="html"><![CDATA[an example of a distill-style blog post and main elements]]></summary></entry><entry><title type="html">a post with github metadata</title><link href="https://liguiye.github.io/blog/2020/github-metadata/" rel="alternate" type="text/html" title="a post with github metadata"/><published>2020-09-28T21:01:00+00:00</published><updated>2020-09-28T21:01:00+00:00</updated><id>https://liguiye.github.io/blog/2020/github-metadata</id><content type="html" xml:base="https://liguiye.github.io/blog/2020/github-metadata/"><![CDATA[<p>A sample blog page that demonstrates the accessing of github meta data.</p> <h2 id="what-does-github-metadata-do">What does Github-MetaData do?</h2> <ul> <li>Propagates the site.github namespace with repository metadata</li> <li>Setting site variables : <ul> <li>site.title</li> <li>site.description</li> <li>site.url</li> <li>site.baseurl</li> </ul> </li> <li>Accessing the metadata - duh.</li> <li>Generating edittable links.</li> </ul> <h2 id="additional-reading">Additional Reading</h2> <ul> <li>If you’re recieving incorrect/missing data, you may need to perform a Github API<a href="https://github.com/jekyll/github-metadata/blob/master/docs/authentication.md"> authentication</a>.</li> <li>Go through this <a href="https://jekyll.github.io/github-metadata/">README</a> for more details on the topic.</li> <li><a href="https://github.com/jekyll/github-metadata/blob/master/docs/site.github.md">This page</a> highlights all the feilds you can access with github-metadata. <br/></li> </ul> <h2 id="example-metadata">Example MetaData</h2> <ul> <li>Host Name :</li> <li>URL :</li> <li>BaseURL :</li> <li>Archived :</li> <li>Contributors :</li> </ul>]]></content><author><name></name></author><category term="sample-posts"/><category term="external-services"/><summary type="html"><![CDATA[a quick run down on accessing github metadata.]]></summary></entry><entry><title type="html">a post with math</title><link href="https://liguiye.github.io/blog/2015/math/" rel="alternate" type="text/html" title="a post with math"/><published>2015-10-20T15:12:00+00:00</published><updated>2015-10-20T15:12:00+00:00</updated><id>https://liguiye.github.io/blog/2015/math</id><content type="html" xml:base="https://liguiye.github.io/blog/2015/math/"><![CDATA[<p>This theme supports rendering beautiful math in inline and display modes using <a href="https://www.mathjax.org/">MathJax 3</a> engine. You just need to surround your math expression with <code class="language-plaintext highlighter-rouge">$$</code>, like <code class="language-plaintext highlighter-rouge">$$ E = mc^2 $$</code>. If you leave it inside a paragraph, it will produce an inline expression, just like \(E = mc^2\).</p> <p>To use display mode, again surround your expression with <code class="language-plaintext highlighter-rouge">$$</code> and place it as a separate paragraph. Here is an example:</p> \[\sum_{k=1}^\infty |\langle x, e_k \rangle|^2 \leq \|x\|^2\] <p>You can also use <code class="language-plaintext highlighter-rouge">\begin{equation}...\end{equation}</code> instead of <code class="language-plaintext highlighter-rouge">$$</code> for display mode math. MathJax will automatically number equations:</p> <p>\begin{equation} \label{eq:cauchy-schwarz} \left( \sum_{k=1}^n a_k b_k \right)^2 \leq \left( \sum_{k=1}^n a_k^2 \right) \left( \sum_{k=1}^n b_k^2 \right) \end{equation}</p> <p>and by adding <code class="language-plaintext highlighter-rouge">\label{...}</code> inside the equation environment, we can now refer to the equation using <code class="language-plaintext highlighter-rouge">\eqref</code>.</p> <p>Note that MathJax 3 is <a href="https://docs.mathjax.org/en/latest/upgrading/whats-new-3.0.html">a major re-write of MathJax</a> that brought a significant improvement to the loading and rendering speed, which is now <a href="http://www.intmath.com/cg5/katex-mathjax-comparison.php">on par with KaTeX</a>.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="math"/><summary type="html"><![CDATA[an example of a blog post with some math]]></summary></entry><entry><title type="html">a post with code</title><link href="https://liguiye.github.io/blog/2015/code/" rel="alternate" type="text/html" title="a post with code"/><published>2015-07-15T15:09:00+00:00</published><updated>2015-07-15T15:09:00+00:00</updated><id>https://liguiye.github.io/blog/2015/code</id><content type="html" xml:base="https://liguiye.github.io/blog/2015/code/"><![CDATA[<p>This theme implements a built-in Jekyll feature, the use of Rouge, for syntax highlighting. It supports more than 100 languages. This example is in C++. All you have to do is wrap your code in a liquid tag:</p> <p>{% highlight c++ linenos %} <br/> code code code <br/> {% endhighlight %}</p> <p>The keyword <code class="language-plaintext highlighter-rouge">linenos</code> triggers display of line numbers. Produces something like this:</p> <figure class="highlight"><pre><code class="language-c--" data-lang="c++"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td class="code"><pre><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="k">const</span> <span class="err">\</span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>
    <span class="n">string</span> <span class="n">myString</span><span class="p">;</span>

    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"input a string: "</span><span class="p">;</span>
    <span class="n">getline</span><span class="p">(</span><span class="n">cin</span><span class="p">,</span> <span class="n">myString</span><span class="p">);</span>
    <span class="kt">int</span> <span class="n">length</span> <span class="o">=</span> <span class="n">myString</span><span class="p">.</span><span class="n">length</span><span class="p">();</span>

    <span class="kt">char</span> <span class="n">charArray</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">char</span> <span class="o">*</span> <span class="p">[</span><span class="n">length</span><span class="p">];</span>

    <span class="n">charArray</span> <span class="o">=</span> <span class="n">myString</span><span class="p">;</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">length</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">){</span>
        <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">charArray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="s">" "</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></td></tr></tbody></table></code></pre></figure>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[an example of a blog post with some code]]></summary></entry><entry><title type="html">a post with images</title><link href="https://liguiye.github.io/blog/2015/images/" rel="alternate" type="text/html" title="a post with images"/><published>2015-05-15T21:01:00+00:00</published><updated>2015-05-15T21:01:00+00:00</updated><id>https://liguiye.github.io/blog/2015/images</id><content type="html" xml:base="https://liguiye.github.io/blog/2015/images/"><![CDATA[<p>This is an example post with image galleries.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/9-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/9-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/9-1400.webp"/> <img src="/assets/img/9.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/7-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/7-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/7-1400.webp"/> <img src="/assets/img/7.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> A simple, elegant caption looks good between image rows, after each row, or doesn't have to be there at all. </div> <p>Images can be made zoomable. Simply add <code class="language-plaintext highlighter-rouge">data-zoomable</code> to <code class="language-plaintext highlighter-rouge">&lt;img&gt;</code> tags that you want to make zoomable.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/8-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/8-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/8-1400.webp"/> <img src="/assets/img/8.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/10-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/10-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/10-1400.webp"/> <img src="/assets/img/10.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>The rest of the images in this post are all zoomable, arranged into different mini-galleries.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/11-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/11-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/11-1400.webp"/> <img src="/assets/img/11.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/12-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/12-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/12-1400.webp"/> <img src="/assets/img/12.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/7-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/7-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/7-1400.webp"/> <img src="/assets/img/7.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="images"/><summary type="html"><![CDATA[this is what included images could look like]]></summary></entry></feed>